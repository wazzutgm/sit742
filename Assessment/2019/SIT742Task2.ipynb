{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SIT742Assignment2.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "language_info": {
      "mimetype": "text/x-python",
      "nbconvert_exporter": "python",
      "version": "3.5.5",
      "name": "python",
      "file_extension": ".py",
      "pygments_lexer": "ipython3",
      "codemirror_mode": {
        "version": 3,
        "name": "ipython"
      }
    },
    "kernelspec": {
      "display_name": "Python 3.5",
      "name": "python3",
      "language": "python"
    }
  },
  "cells": [
    {
      "metadata": {
        "id": "_th7e2nu0At7",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# SIT742: Modern Data Science \n",
        "**(Assessment Task 02: Bank Marketing Data Analytics)**\n",
        "\n",
        "---\n",
        "- Materials in this module include resources collected from various open-source online repositories.\n",
        "- You are free to use, change and distribute this package.\n",
        "\n",
        "Prepared by **SIT742 Teaching Team**\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "**Project Group Information:**\n",
        "\n",
        "- Names:\n",
        "- Student IDs:\n",
        "- Emails:\n",
        "\n",
        "---"
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "eASNvREtBU9G"
      },
      "cell_type": "markdown",
      "source": [
        "# 1.Import Spark"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "duCJfMrnGu00",
        "cellView": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!pip install wget\n",
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n",
        "!wget -q https://archive.apache.org/dist/spark/spark-2.4.0/spark-2.4.0-bin-hadoop2.7.tgz\n",
        "!tar xf spark-2.4.0-bin-hadoop2.7.tgz\n",
        "!pip install -q findspark\n",
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = \"/content/spark-2.4.0-bin-hadoop2.7\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "aGOo805LA-fM",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import findspark\n",
        "findspark.init()\n",
        "from pyspark.sql import SparkSession "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "K7bEtO_fBZmE"
      },
      "cell_type": "markdown",
      "source": [
        "# 2.Read and check data"
      ]
    },
    {
      "metadata": {
        "id": "EADPspOv0Auh",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import wget\n",
        "link_to_data = 'https://github.com/tulip-lab/sit742/raw/master/Assessment/2019/data/bank.csv'\n",
        "DataSet = wget.download(link_to_data)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "tiM-PiiR0Aup",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "FQ8Ts9eZBA-M",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Import the 'bank.csv' as a Spark dataframe and name it as df\n",
        "spark = SparkSession.builder.appName('ml-bank').getOrCreate()\n",
        "df = spark.read.csv('bank.csv', header = True, inferSchema = True) \n",
        "df.printSchema() \n",
        "df.show(5)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "XJGWVc0yB0UA",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Check data distribution\n",
        "# You may use printSchema() "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "wKQMhrtFChHa"
      },
      "cell_type": "markdown",
      "source": [
        "# 3.Select features"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "VU5xMqN_RyM2",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Select features ('age', 'job', 'marital', 'education', 'default', 'balance', 'housing', 'loan', 'campaign', 'pdays', 'previous', 'poutcome', 'deposit') as df2\n",
        "df2=\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "vwF5sqRYa_eI",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Remove invalid rows/records using spark.sql "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "A_T8qvxzR-oI",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Covert categorical features to metric features using One hot encoding\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "pOqHERYJCQuC"
      },
      "cell_type": "markdown",
      "source": [
        "## 3.1 normalisation"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "cfL6_sca5VwI",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Apply Min-Max normalisation on each attribute using MinMaxScaler  \n",
        "from pyspark.ml.feature import MinMaxScaler "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "9trUY7ZgCzhW"
      },
      "cell_type": "markdown",
      "source": [
        "# 4.Unsupervised learning"
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "KTQfUch2Cmmi"
      },
      "cell_type": "markdown",
      "source": [
        "## 4.1 K-means"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "dGGZI70Ohqgg",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Perform unsupervised learning on df2 with k-means \n",
        "# You can use whole df2 as both training and testing data, \n",
        "# Evaluate the clustering result using Accuracy.  \n",
        "from pyspark.ml.clustering import KMeans\n",
        "from pyspark.ml.evaluation import ClusteringEvaluator\n",
        "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
        "from pyspark.ml.evaluation import BinaryClassificationEvaluator "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "FHom8o2KCt36"
      },
      "cell_type": "markdown",
      "source": [
        "## 4.2 PCA"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "wT4cx5uGTjmj",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Generate a scatter plot using the first two PCA components to investigate the data distribution.\n",
        "from pyspark.ml.feature import PCA\n",
        "from pyspark.ml.linalg import Vectors"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "ulp_uILXCv4Z"
      },
      "cell_type": "markdown",
      "source": [
        "# 5.Supervised learning"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "0O7tszcPfnHN",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train, test = df2.randomSplit([0.7, 0.3], seed = 742)\n",
        "print(\"Training Dataset Count: \" + str(train.count()))\n",
        "print(\"Test Dataset Count: \" + str(test.count()))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "2SsHdh7YC-eN"
      },
      "cell_type": "markdown",
      "source": [
        "## 5.1 LogisticRegression"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "Vqo_ywFQYxSj",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Logistic Regression\n",
        "from pyspark.ml.classification import LogisticRegression\n",
        "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
        "from pyspark.ml.evaluation import BinaryClassificationEvaluator "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "hANwFUzhgG83",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Exam the coefficients"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "evM5eiJoDHw2"
      },
      "cell_type": "markdown",
      "source": [
        "## 5.2 Decision tree"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "He4mlHb7hBoY",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Decision tree\n",
        "from pyspark.ml.classification import DecisionTreeClassifier "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "CaE-Z_IlDKXF"
      },
      "cell_type": "markdown",
      "source": [
        "## 5.3 NaiveBayes"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "v2XL6I0t7irt",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#NaiveBayes\n",
        "from pyspark.ml.classification import NaiveBayes\n",
        "from pyspark.ml.evaluation import MulticlassClassificationEvaluator"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}